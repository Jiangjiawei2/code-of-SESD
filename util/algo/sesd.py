# util/algo/sesd.py
import torch
import torch.nn as nn
import numpy as np
import os
import traceback
from tqdm import tqdm
import lpips
import fastmri
from util.algo.utils import compute_metrics as compute_metrics_util, log_metrics_to_tensorboard, ESWithWMV

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æµ‹é‡ç®—å­æŠ½è±¡å±‚ (Measurement Operator Abstraction)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MeasurementOperator:
    """SESDä¸­æµ‹é‡ç®—å­çš„åŸºç±»"""
    def forward(self, x, mask=None):
        raise NotImplementedError
    
    def project(self, x, y, mask=None, alpha=None):
        """
        å°†xæŠ•å½±åˆ°ç”±yå®šä¹‰çš„æµ‹é‡æµå½¢ä¸Š
        è¿”å›æ•°æ®ä¸€è‡´æ€§æ›´æ–° v_k
        """
        raise NotImplementedError


class StandardOperator(MeasurementOperator):
    """æ ‡å‡†ç®—å­ï¼šç”¨äºå»æ¨¡ç³Šã€è¶…åˆ†è¾¨ç‡ã€ä¿®å¤ç­‰ä»»åŠ¡"""
    def __init__(self, operator_module, device, mu=1.0):
        self.operator = operator_module
        self.device = device
        self.mu = torch.tensor(mu, device=device)

    def forward(self, x, mask=None):
        return self.operator.forward(x, mask=mask) if mask is not None else self.operator.forward(x)

    def project(self, x, y, mask=None, alpha=None):
        """åŸºäºæ¢¯åº¦ä¸‹é™çš„æŠ•å½±ï¼ˆé€‚ç”¨äºä¸€èˆ¬çº¿æ€§/éçº¿æ€§é—®é¢˜ï¼‰"""
        with torch.enable_grad():
            x_in = x.detach().clone().requires_grad_(True)
            Ax = self.forward(x_in, mask)
            
            # ä½¿ç”¨MSEç±»æ¢¯åº¦ä¿æŒç¨³å®šæ€§
            loss = torch.linalg.norm(y - Ax)
            grad = torch.autograd.grad(loss, x_in)[0]
            
            v_k = x - self.mu * grad
        return v_k


class MRIOperator(MeasurementOperator):
    """MRIä¸“ç”¨ç®—å­ï¼šå¤„ç†å¤šçº¿åœˆkç©ºé—´æ•°æ®"""
    def __init__(self, device, k_under, mask_dc, csm, img_min, img_max):
        self.device = device
        self.k_under = k_under
        self.mask_dc = mask_dc
        self.csm = csm
        self.img_min = img_min
        self.img_max = img_max
        
        # å†…éƒ¨æ¨¡å—
        self.dc_layer = DC_layer_CSM().to(device)
        self.mri_fwd = mri_forward().to(device)

    def forward(self, x, mask=None):
        return self.mri_fwd(x, self.mask_dc, self.csm, self.img_min, self.img_max)

    def project(self, x, y, mask=None, alpha=None):
        """æ•°æ®ä¸€è‡´æ€§å±‚"""
        # xæ˜¯[B, C, H, W]ï¼ŒMRIä»£ç ä½¿ç”¨x[:, 0:1, ...]
        x_single = x[:, 0:1, :, :]
        v_k_single = self.dc_layer(x_single, self.k_under, self.mask_dc, self.csm, self.img_min, self.img_max)
        
        # å¦‚æœ‰å¿…è¦ï¼Œå¹¿æ’­å›Cé€šé“ï¼ˆä¾‹å¦‚ç”¨äºæ¨¡å‹è¾“å…¥ï¼‰
        v_k = v_k_single.repeat(1, x.shape[1], 1, 1).contiguous()
        return v_k


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ ¸å¿ƒç®—æ³•ï¼šSESD with ALES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def SESD_Core(
    model, sampler, measurement_cond_fn, ref_img, y_n,
    model_config, operator: MeasurementOperator, fname,
    iter_step, iteration, denoiser_step, lr, out_path,
    loss_fn_alex, device, mask_sampling=None, random_seed=None,
    writer=None, img_index=None,
    # ALES å‚æ•°
    use_ales=True,
    ales_window_size=10,
    ales_var_threshold=1e-3,
    ales_alpha=1e-3,
    ales_patience=20,
    ales_min_epochs=30
):
    """
    SESD: Score Evolved Shortcut Diffusion with ALES
    
    ALESå‚æ•°:
        use_ales: æ˜¯å¦å¯ç”¨ALESæ—©åœ
        ales_window_size: æ—¶é—´åŠ æƒæ–¹å·®çš„çª—å£å¤§å°
        ales_var_threshold: æ–¹å·®é˜ˆå€¼Î´_v
        ales_alpha: æŸå¤±é˜ˆå€¼Î±
        ales_patience: è€å¿ƒå‚æ•°P
        ales_min_epochs: æœ€å°è¿­ä»£æ¬¡æ•°E_min
    """
    if random_seed is not None:
        torch.manual_seed(random_seed)
        if torch.cuda.is_available(): torch.cuda.manual_seed_all(random_seed)
        np.random.seed(random_seed)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # é…ç½®è®°å½•åˆ°TensorBoard
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    algo_name = "SESD"
    if writer and img_index is not None:
        config_text = (
            f'Algorithm: {algo_name}\n'
            f'Iterations: {iteration}\n'
            f'LR: {lr}\n'
            f'Shortcut Step t*: {iter_step}\n'
            f'Total Steps T: {denoiser_step}\n'
            f'ALES Enabled: {use_ales}\n'
        )
        if use_ales:
            config_text += (
                f'ALES Window Size W: {ales_window_size}\n'
                f'ALES Var Threshold Î´_v: {ales_var_threshold}\n'
                f'ALES Alpha Î±: {ales_alpha}\n'
                f'ALES Patience P: {ales_patience}\n'
                f'ALES Min Epochs E_min: {ales_min_epochs}\n'
            )
        writer.add_text(f'{algo_name}/Image_{img_index}/Config', config_text, 0)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1. åˆå§‹åŒ–Zåœ¨t*ï¼ˆæ·å¾„ï¼‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Z_channels = 3  # æ ‡å‡†RGB
    Z = torch.randn((1, Z_channels, model_config['image_size'], model_config['image_size']), device=device)
    
    current_state = Z
    with torch.no_grad():
        # æ·å¾„ï¼šä»Té‡‡æ ·åˆ°t*ï¼ˆiter_stepï¼‰
        for i in range(denoiser_step - 1, iter_step - 1, -1):
            t_val = torch.tensor([i] * Z.shape[0], device=device)
            current_state, _ = sampler.p_sample(
                model=model, x=current_state, t=t_val,
                measurement=y_n, measurement_cond_fn=measurement_cond_fn, mask=mask_sampling
            )
    
    initial_shortcut_state = current_state.detach().clone()
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2. ä¼˜åŒ–è®¾ç½®
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    x_opt = initial_shortcut_state.requires_grad_(True)
    
    # å¯å­¦ä¹ çš„å¹³è¡¡å‚æ•°Î»ï¼ˆåœ¨rebuttalä¸­renamed from alphaï¼‰
    lambda_param = torch.tensor(0.5, requires_grad=True, device=device) 
    
    optimizer = torch.optim.Adam([
        {'params': x_opt, 'lr': lr},
        {'params': lambda_param, 'lr': lr * 0.1}  # Î»ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡
    ])
    
    data_fidelity_loss_fn = nn.L1Loss().to(device)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3. ALESæ—©åœå™¨åˆå§‹åŒ–
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if use_ales:
        early_stopper = ESWithWMV(
            window_size=ales_window_size,
            var_threshold=ales_var_threshold,
            alpha=ales_alpha,
            patience=ales_patience,
            min_epochs=ales_min_epochs,
            verbose=True
        )
    
    best_psnr = -float('inf')
    best_sample = None
    best_metrics = None
    best_epoch = 0
    
    psnrs_log = []
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4. ä¼˜åŒ–å¾ªç¯ï¼ˆå¸¦ALESï¼‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pbar = tqdm(range(iteration), desc=f"SESD Opt. Img {img_index or ''}")
    for epoch in pbar:
        model.eval()
        optimizer.zero_grad()
        
        # â•â•â• A. ä»å½“å‰x_{t*}å»å™ªåˆ°x_0ï¼ˆè¿‘ä¼¼ï¼‰ â•â•â•
        denoised_state = x_opt
        for i in range(iter_step - 1, -1, -1):
             t_val = torch.tensor([i] * denoised_state.shape[0], device=device)
             denoised_state, _ = sampler.p_sample(
                 model=model, x=denoised_state, t=t_val,
                 measurement=y_n, measurement_cond_fn=measurement_cond_fn, mask=mask_sampling
             )
        
        # â•â•â• B. æ•°æ®ä¸€è‡´æ€§åŠ é€Ÿ â•â•â•
        v_k = operator.project(denoised_state, y_n, mask=mask_sampling)
        
        # â•â•â• C. èåˆï¼ˆä½¿ç”¨Î»è€ŒéÎ±ï¼‰ â•â•â•
        current_lambda = torch.sigmoid(lambda_param)
        x_k_fusion = current_lambda * denoised_state + (1 - current_lambda) * v_k
        
        # â•â•â• D. æŸå¤±è®¡ç®— â•â•â•
        est_measurement = operator.forward(x_k_fusion, mask=mask_sampling)
        loss = data_fidelity_loss_fn(est_measurement, y_n)
        
        # â•â•â• E. åå‘ä¼ æ’­ â•â•â•
        loss.backward()
        optimizer.step()
        
        # â•â•â• F. æŒ‡æ ‡è®°å½• & ALESæ£€æŸ¥ â•â•â•
        with torch.no_grad():
            sample_eval = x_k_fusion
            if ref_img.shape[1] == 1 and x_k_fusion.shape[1] == 3:
                sample_eval = x_k_fusion[:, 0:1, :, :]
                
            curr_metrics = compute_metrics_util(
                sample=sample_eval, ref_img=ref_img, device=device, loss_fn_alex=loss_fn_alex
            )
            curr_psnr = curr_metrics.get('psnr', float('nan'))
            psnrs_log.append(curr_psnr)
            
            pbar.set_postfix({
                'loss': loss.item(), 
                'Î»': current_lambda.item(), 
                'psnr': curr_psnr
            })
            
            # æ›´æ–°æœ€ä½³æ ·æœ¬
            if not np.isnan(curr_psnr) and curr_psnr > best_psnr:
                best_psnr = curr_psnr
                best_sample = x_k_fusion.detach().clone()
                best_metrics = curr_metrics.copy()
                best_epoch = epoch
                
            # TensorBoardè®°å½•
            if writer and img_index is not None:
                log_metrics_to_tensorboard(writer, {
                    'Loss': loss.item(), 
                    'PSNR': curr_psnr, 
                    'SSIM': curr_metrics.get('ssim'),
                    'Lambda': current_lambda.item()
                }, epoch, img_index, prefix=f'{algo_name}/Epoch')
            
            # â•â•â• ALESæ—©åœæ£€æŸ¥ â•â•â•
            if use_ales:
                # ALESéœ€è¦å›¾åƒå’ŒæŸå¤±æ¥åˆ¤æ–­
                should_stop = early_stopper(epoch, x_k_fusion, loss.item())
                if should_stop:
                    print(f"\nğŸ›‘ ALESè§¦å‘æ—©åœäºepoch {epoch+1}")
                    if writer and img_index is not None:
                        writer.add_text(
                            f'{algo_name}/Image_{img_index}/ALES_Stop',
                            f'ALES stopped at epoch {epoch+1}', epoch
                        )
                    break

    if best_sample is None: 
        best_sample = x_k_fusion.detach()
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 5. ä¿å­˜ç»“æœ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    save_subdir = 'sesd_results'
    _save_algo_image(
        best_sample, 
        os.path.join(out_path, f'recon_{save_subdir}', fname), 
        is_mri_grayscale=(ref_img.shape[1]==1)
    )
    
    print(f"SESD Final {fname}: Best PSNR {best_psnr:.4f} at epoch {best_epoch}")
    
    return best_sample, best_metrics, {'psnrs': psnrs_log}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å…¼å®¹æ€§åŒ…è£…å™¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def SESD(
    model, sampler, measurement_cond_fn, ref_img, y_n, device, 
    model_config, measure_config, operator, fname,
    iter_step=3, iteration=300, denoiser_step=10, lr=0.02, 
    out_path='./outputs/', mask=None, random_seed=None, 
    writer=None, img_index=None, loss_fn_alex=None,
    # ALESå‚æ•°ï¼ˆç¬¦åˆè®ºæ–‡ä¸­çš„é»˜è®¤å€¼ï¼‰
    use_ales=True,
    ales_window_size=10,
    ales_var_threshold=1e-3,
    ales_alpha=1e-3,
    ales_patience=20,
    ales_min_epochs=30,
    **kwargs
):
    """
    æ ‡å‡†SESDåŒ…è£…å™¨ï¼ˆè¶…åˆ†ã€ä¿®å¤ã€å»æ¨¡ç³Šï¼‰
    """
    if loss_fn_alex is None: 
        loss_fn_alex = lpips.LPIPS(net='alex').to(device)
    
    # åˆ›å»ºæ ‡å‡†ç®—å­
    std_operator = StandardOperator(operator, device)
    
    return SESD_Core(
        model, sampler, measurement_cond_fn, ref_img, y_n,
        model_config, std_operator, fname,
        iter_step, iteration, denoiser_step, lr, out_path,
        loss_fn_alex, device, mask_sampling=mask, random_seed=random_seed,
        writer=writer, img_index=img_index,
        use_ales=use_ales, 
        ales_window_size=ales_window_size,
        ales_var_threshold=ales_var_threshold,
        ales_alpha=ales_alpha,
        ales_patience=ales_patience,
        ales_min_epochs=ales_min_epochs
    )


def SESD_MRI(
    model, sampler, measurement_cond_fn, ref_img, y_n, 
    k_under, mask_dc, csm, img_min, img_max,
    device, model_config, measure_config, operator, fname,
    iter_step=3, iteration=300, denoiser_step=10, lr=0.02,
    out_path='./outputs/', random_seed=None,
    writer=None, img_index=None, loss_fn_alex=None,
    # ALESå‚æ•°
    use_ales=True,
    ales_window_size=10,
    ales_var_threshold=1e-3,
    ales_alpha=1e-3,
    ales_patience=20,
    ales_min_epochs=30,
    **kwargs
):
    """
    MRIä¸“ç”¨SESDåŒ…è£…å™¨
    """
    if loss_fn_alex is None: 
        loss_fn_alex = lpips.LPIPS(net='alex').to(device)
    
    # åˆ›å»ºMRIç®—å­
    mri_operator = MRIOperator(device, k_under, mask_dc, csm, img_min, img_max)
    
    return SESD_Core(
        model, sampler, measurement_cond_fn, ref_img, y_n,
        model_config, mri_operator, fname,
        iter_step, iteration, denoiser_step, lr, out_path,
        loss_fn_alex, device, mask_sampling=mask_dc, random_seed=random_seed,
        writer=writer, img_index=img_index,
        use_ales=use_ales,
        ales_window_size=ales_window_size,
        ales_var_threshold=ales_var_threshold,
        ales_alpha=ales_alpha,
        ales_patience=ales_patience,
        ales_min_epochs=ales_min_epochs
    )


# å‘åå…¼å®¹çš„åˆ«å
acce_RED_diff = SESD
acce_RED_diff_mri = SESD_MRI


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è¾…åŠ©å‡½æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _save_algo_image(tensor_data, file_path, is_kernel=False, is_mri_grayscale=False):
    """ä¿å­˜å¼ é‡å›¾åƒåˆ°æ–‡ä»¶"""
    import matplotlib.pyplot as plt
    try:
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        img = tensor_data.detach().cpu()
        if img.dim() == 4: img = img[0]
        
        if is_mri_grayscale: 
             if img.dim() == 3 and img.shape[0] == 3: img = img[0] 
             if img.dim() == 3: img = img.squeeze(0)
             plt.imsave(file_path, img.numpy(), cmap='gray')
        else:
             if img.dim() == 3 and img.shape[0] == 1: 
                 img = img.squeeze(0)
                 plt.imsave(file_path, img.numpy(), cmap='gray')
             else:
                 img = img.permute(1, 2, 0).numpy()
                 img = (img + 1) / 2
                 img = np.clip(img, 0, 1)
                 plt.imsave(file_path, img)
    except Exception as e:
        print(f"Error saving {file_path}: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MRIå·¥å…·å‡½æ•°ï¼ˆæœ€å°é›†åˆï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def kspace2rss(kspace_data_real): 
    """ä»å¤šçº¿åœˆkç©ºé—´æ•°æ®è®¡ç®—RSSå›¾åƒ"""
    kspace_complex = torch.view_as_complex(kspace_data_real.contiguous())
    image_space_coils = fastmri.ifft2c(kspace_complex) 
    abs_coil_images = fastmri.complex_abs(image_space_coils)
    rss_image = fastmri.rss(abs_coil_images, dim=1) 
    return rss_image.unsqueeze(1) 


def rss_to_kspace(rss_image_normalized, csm, img_min, img_max):
    """å°†RSSå›¾åƒè½¬æ¢å›kç©ºé—´æ•°æ®"""
    rss_image = ((rss_image_normalized.squeeze(1) + 1.0) / 2.0) * \
                (img_max.view(-1,1,1) - img_min.view(-1,1,1)) + img_min.view(-1,1,1)
    csm_complex = torch.view_as_complex(csm.contiguous())
    coil_images = csm_complex * rss_image.unsqueeze(1)
    kspace = fastmri.fft2c(coil_images)
    return torch.view_as_real(kspace.contiguous())


class DC_layer_CSM(nn.Module):
    """æ•°æ®ä¸€è‡´æ€§å±‚ï¼ˆä½¿ç”¨çº¿åœˆçµæ•åº¦å›¾ï¼‰"""
    def __init__(self): 
        super().__init__()
        
    def forward(self, x_rss, k_under, mask, csm, img_min, img_max):
        k_est = rss_to_kspace(x_rss, csm, img_min, img_max)
        mask_bool = mask.squeeze(-1)
        k_dc = (1 - mask_bool.float()) * torch.view_as_complex(k_est.contiguous()) + \
               mask_bool.float() * torch.view_as_complex(k_under.contiguous())
        rss_new = kspace2rss(torch.view_as_real(k_dc))
        denom = (img_max.view(-1,1,1,1) - img_min.view(-1,1,1,1) + 1e-7)
        rss_norm = ((rss_new - img_min.view(-1,1,1,1)) / denom) * 2.0 - 1.0
        return torch.clamp(rss_norm, -1.0, 1.0)


class mri_forward(nn.Module):
    """MRIå‰å‘ç®—å­"""
    def __init__(self): 
        super().__init__()
        
    def forward(self, x_rss, mask, csm, img_min, img_max):
        k_full = rss_to_kspace(x_rss, csm, img_min, img_max)
        mask_to_apply = mask
        if mask_to_apply.dim() == 2: 
            mask_to_apply = mask_to_apply.unsqueeze(0).unsqueeze(0).unsqueeze(-1)
        if mask_to_apply.shape[-1] == 1: 
            mask_to_apply = mask_to_apply.squeeze(-1)
        k_under = torch.view_as_complex(k_full.contiguous()) * mask_to_apply.unsqueeze(1)
        rss_under = kspace2rss(torch.view_as_real(k_under))
        denom = (img_max.view(-1,1,1,1) - img_min.view(-1,1,1,1) + 1e-7)
        rss_norm = ((rss_under - img_min.view(-1,1,1,1)) / denom) * 2.0 - 1.0
        return torch.clamp(rss_norm, -1.0, 1.0)
